# AI-Knowledge-Base

## NVIDIA CUDA

- [CUDA Toolkit](/nvidia-cuda/cuda-toolkit/README.md)
- [Container Toolkit](/nvidia-cuda/container-toolkit/README.md)

## LLMs

### Local LLMs

- **[NVIDIA NIM](https://docs.nvidia.com/nim/large-language-models/latest/introduction.html) (NVIDIA Inference Microservices)**

- [**Ollama**](/docs/LOCAL-LLM.md)

- **llama.cpp**

### Core techniques

- [RAG + Summarization (Documentation System): Ollama, LangChain, Qdrant](/rag-pipeline/README.md)

- **Prompt Engineering with Chain-of-Thought** - Systematic techniques for better outputs

### Agent Systems

- **AI Agent (LangGraph) and MCP Server** - Intelligent agent with MCP server, function calling and tool use, memory management

- **Orchestration** - Multi-agent systems, complex workflows, state management, Human-in-the-loop

### Model Customization

- **LLM PEFT (Parameter-Efficient Fine-Tuning)** - LLM [fine-tuning and reinforcement learning](https://unsloth.ai/docs/get-started/fine-tuning-llms-guide) with [Unsloth](https://unsloth.ai/docs)

- **Custom Quantization with [llama.cpp](https://github.com/ggml-org/llama.cpp)** - Convert and quantize a model

### Model Evaluation

- **Model Evaluation & Benchmarking** - lm-eval and RAGAS

## GPU Computing

- [NVIDIA CUDA Python, CuPy and cuDF (GPU-accelerated NumPy/SciPy and Pandas)](/nvidia-cuda/cuda-python/README.md)

- **NVIDIA cuBLAS - GPU-accelerated APIs: Basic Linear Algebra Subprograms and General Matrix Multiplication**

## Machine Learning

## Neural Network - Deep Learning

- **NVIDIA cuDNN (CUDA Deep Neural Network): PyTorch and TensorFlow with GPU support**
