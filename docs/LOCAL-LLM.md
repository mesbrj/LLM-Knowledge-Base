# Ollama

**Pre-requisite on WSL2**
- [Hardware support](https://docs.ollama.com/gpu)
- ***NVIDIA Driver installed only on Windows host***


[Install Ollama and pull models:](https://docs.ollama.com/)
- [deepseek-r1:14b Q4_K_M (size ~9.0GB)](https://ollama.com/library/deepseek-r1:14b)
- [gemma3:12b Q4_K_M (size ~8.1GB)](https://ollama.com/library/gemma3:12b)
- [llama3.1:8b Q8_0 (size ~8.5GB)](https://ollama.com/library/llama3.1:8b-instruct-q8_0)
- [nomic-embed-text:v1.5 F16 (size ~274MB)](https://ollama.com/library/nomic-embed-text:v1.5)

# llama.cpp
- [Local gpt-oss models](https://github.com/ggml-org/llama.cpp/discussions/15396)

# NVIDIA NIM [(NVIDIA Inference Microservices)](https://docs.nvidia.com/nim/large-language-models/latest/introduction.html)
- [Deployment Guide](https://docs.nvidia.com/nim/large-language-models/latest/deployment-guide.html) 
- [Get Started with NVIDIA NIM for LLMs](https://docs.nvidia.com/nim/large-language-models/latest/getting-started.html)

