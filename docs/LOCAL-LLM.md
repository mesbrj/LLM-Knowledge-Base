# Ollama
- [Hardware support](https://docs.ollama.com/gpu)
- [Install Ollama and pull models](https://docs.ollama.com/)
    - [deepseek-r1:14b Q4_K_M (size ~9.0GB)](https://ollama.com/library/deepseek-r1:14b)
    - [gemma3:12b Q4_K_M (size ~8.1GB)](https://ollama.com/library/gemma3:12b)
    - [llama3.1:8b Q8_0 (size ~8.5GB)](https://ollama.com/library/llama3.1:8b-instruct-q8_0)
    - [nomic-embed-text:v1.5 F16 (size ~274MB)](https://ollama.com/library/nomic-embed-text:v1.5)

# llama.cpp
- [Local gpt-oss models](https://github.com/ggml-org/llama.cpp/discussions/15396)